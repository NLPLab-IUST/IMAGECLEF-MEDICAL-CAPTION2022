# -*- coding: utf-8 -*-
"""ImageSemConcept_v6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mZ-I1eZUmTQmpYpvsZjCCeSKeVul3lW3

data aug: normal, clahe_image, clahe_image_crop

w=300

test: clahe_image_crop

dataset_batchsize= 32

epochs = 20

Dropout(0.5)

# Getting Files

imports
"""

import os
import csv
import h5py
import math
import cv2
import spacy, numpy as np
import glob
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras

#import scipy
#from scipy.spatial import distance
import pandas as pd

from torch import nn
import torch.nn.functional as F
import torch.optim as optim
from torch.autograd import Variable

from sklearn.preprocessing import MultiLabelBinarizer
from keras import backend as K
#from sklearn.neighbors import NearestNeighbors

"""mount google drive"""

#from google.colab import drive
#drive.mount('/content/drive')

"""addresses of files"""

path = '../../IMAGECLEF_dataset/'
train_path = path + "train"
valid_path = path + "valid"
test_path = path + "test"

train_number= 83275
valid_number= 7645
test_number= 7601
dataset_batchsize= 64

os.makedirs(path + "results", exist_ok=True)

gt_file = path + "ImageCLEFmedCaption_2022_concept_valid.csv"
candidate_file = path + 'results/valid_concepts_results.csv'

"""# Preprocessing

## Preprocessing Images
"""

def load_images(pixel_x, pixel_y, img_names, folder_path , data_aug=False):
  """normalize and loads image in array format"""
  #jpg_images = glob.glob(img_set_path+'/*.jpg')
  #print(len(jpg_images))
  #jpg_images.sort()
  #jpg_images = jpg_images[start_id:end_id]
  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
  images_list = []

  for img in img_names:
    img_path = folder_path + "/" + img + ".jpg"
    image = cv2.imread(img_path,0)
    if image.shape[0] < image.shape[1]:
      scale_percent = 300 * 100 / image.shape[0]
    else :
      scale_percent = 300 * 100 / image.shape[1]

    h = int(image.shape[1] * scale_percent / 100)
    w = int(image.shape[0] * scale_percent / 100)

    if(data_aug):
      #1 normal_image
      images_list.append(cv2.resize(image, (pixel_y, pixel_x), interpolation = cv2.INTER_AREA))

      #2 clahe_image
      clahe_image = clahe.apply(image) #apply CLAHE 
      images_list.append(cv2.resize(clahe_image, (pixel_y, pixel_x), interpolation = cv2.INTER_AREA))
  
      #3 clahe_image_random_crop
      clahe_image_2 = cv2.resize(clahe_image,(h, w), interpolation = cv2.INTER_LINEAR) #resize image
      clahe_image_2 = tf.image.random_crop(clahe_image_2, size=[pixel_y, pixel_x])
      images_list.append(clahe_image_2)
     
    else:
      clahe_image = clahe.apply(image) #apply CLAHE 
      clahe_image_2 = cv2.resize(clahe_image,(h, w), interpolation = cv2.INTER_LINEAR) #resize image
      clahe_image_2 = tf.image.random_crop(clahe_image_2, size=[pixel_y, pixel_x])
      images_list.append(clahe_image_2)

  x_img = np.array(images_list)
  return x_img

"""## Read All Concepts and their Names"""

concept_ids = pd.read_csv(path + 'concepts.csv', sep="\t")["concept"].tolist()
print(f"read {len(concept_ids)} concepts")

"""## Read Train Images and their Concepts"""

existing_train_img_names = [os.path.splitext(os.path.basename(x))[0] for x in glob.glob(train_path+'/*.jpg')][:train_number]

train_df = pd.read_csv(path + 'ImageCLEFmedCaption_2022_concept_train.csv', delimiter="\t", index_col="ID").filter(items=existing_train_img_names, axis=0)
print(f"read {len(train_df)} train images")

"""## Read Validation Images and their Concepts"""

existing_valid_img_names = [os.path.splitext(os.path.basename(x))[0] for x in glob.glob(valid_path+'/*.jpg')][:valid_number]

valid_df = pd.read_csv(path + 'ImageCLEFmedCaption_2022_concept_valid.csv', delimiter="\t", index_col="ID").filter(items=existing_valid_img_names, axis=0)
print(f"read {len(valid_df)} valid images")

train_img_names = train_df.index.values.tolist()
valid_img_names = valid_df.index.values.tolist()

"""##MLC

resoures:
https://github.com/JiaweiZhao-git/Awesome-Multi-label-Image-Recognition

turn CUIs to binary
"""

my_MultiLabelBinarizer = MultiLabelBinarizer(classes=concept_ids)
my_MultiLabelBinarizer.fit([concept_ids])

#my_MultiLabelBinarizer.classes_

#y_train_cui_one_hot = my_MultiLabelBinarizer.transform(list(train_image_concept_dict.values()))

#y_val_cui_one_hot = my_MultiLabelBinarizer.transform(list(valid_image_concept_dict.values()))

"""## Data Generator"""

class My_Custom_Generator(tf.keras.utils.Sequence) :
  
  def __init__(self, image_filenames, batch_size, folder_path, concepts_df, is_train) :
    self.image_filenames = image_filenames
    self.batch_size = batch_size
    self.folder_path = folder_path
    self.concepts_df = concepts_df
    self.is_train = is_train
    #print(self.is_train)
    
    
  def __len__(self) :
    return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)
  
  
  def __getitem__(self, idx) :
    batch_names = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]
    batch_x  = load_images(299, 299, batch_names, self.folder_path, data_aug=self.is_train )
    
    batch_x = np.expand_dims(batch_x, axis = -1)
    batch_x = tf.image.grayscale_to_rgb(
        tf.convert_to_tensor(batch_x),
        name=None
    )
    batch_y = self.get_labels(batch_names)

    if self.is_train:
      y_rep = np.tile(batch_y,3).reshape(batch_x.shape[0],-1)
      return batch_x, y_rep
    return batch_x, batch_y

  def get_labels(self, img_names):
    if self.concepts_df is None:
      return np.zeros((len(img_names), len(my_MultiLabelBinarizer.classes_)))
    return my_MultiLabelBinarizer.transform(self.concepts_df.loc[img_names]["cuis"].apply(lambda x: x.strip(";").split(";")).values)

gen_train = My_Custom_Generator(train_img_names, dataset_batchsize, folder_path=train_path, concepts_df=train_df, is_train=True)
gen_valid = My_Custom_Generator(valid_img_names, dataset_batchsize, folder_path=valid_path, concepts_df=valid_df, is_train=False)
print("created train and valid data generators")

"""#nural model

delete unnecessary image_concept_dict
"""

#del train_image_concept_dict
#del valid_image_concept_dict

"""delete unnecessary img_array_images"""

#del x_train_img_array_images
#del x_val_img_array_images

"""##InceptionV3

InceptionV3 pretrain
"""

inceptionV3 = tf.keras.applications.InceptionV3(
    include_top=True,
    weights="imagenet",
)

#inceptionV3.trainable = False
x = inceptionV3.layers[-2].output
x = tf.keras.layers.Dropout(0.5)(x)
inceptionV3_prediction_layer = tf.keras.layers.Dense(len(my_MultiLabelBinarizer.classes_), activation=tf.keras.activations.sigmoid )(x)
fine_tuned_inceptionV3 = tf.keras.models.Model(inputs = inceptionV3.input, outputs = inceptionV3_prediction_layer)

#tf.keras.utils.plot_model(fine_tuned_inceptionV3, show_shapes=True)

"""#training

f1 metric
"""

def f1_weighted(true, pred):
    ground_positives = K.sum(true, axis=0) + K.epsilon()       # = TP + FN
    pred_positives = K.sum(pred, axis=0) + K.epsilon()         # = TP + FP
    true_positives = K.sum(true * pred, axis=0) + K.epsilon()  # = TP
    
    precision = true_positives / pred_positives 
    recall = true_positives / ground_positives

    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())

    weighted_f1 = f1 * ground_positives / K.sum(ground_positives) 
    weighted_f1 = K.sum(weighted_f1)

    
    return weighted_f1

"""compile model"""

initial_learning_rate = 0.009
fine_tuned_inceptionV3.compile(loss = 'binary_crossentropy', optimizer="adam", metrics = ['acc', f1_weighted])

"""Create a callback that saves the model's weights"""

'''
checkpoint_path = path + "weights/models_weights-{epoch:02d}.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

weights_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)

'''

"""train"""

class SaveResultsCallback(tf.keras.callbacks.Callback):
        
    def on_epoch_end(self, epoch, logs={}):
      if ((epoch+1) % 4 != 0 and (epoch+1) != 1):
        return

      self.model.save_weights(path + "fateme" + f"/weights/e{epoch+1}_weights.h5", overwrite=True)

history = fine_tuned_inceptionV3.fit(
    x=gen_train,
    epochs = 20,
    validation_data=gen_valid,
    verbose= 1,
    #callbacks=[SaveResultsCallback()]
)

#fine_tuned_inceptionV3.save(path + 'fateme/weights/fine_tuned_inceptionV3_weights.h5')

"""#evaluation

predict valid images
"""

valid_img_features = fine_tuned_inceptionV3.predict(gen_valid)

"""save predicted cui one hots to a npy file"""

with open( result_path +'/valid_img_features.npy', 'wb') as f:
    np.save(f,valid_img_features,allow_pickle=True)

"""load predicted cui one hots from npy file"""

with open(result_path +'/valid_img_features.npy', 'rb') as f:
    valid_img_features = np.load(f,allow_pickle=True)

"""normalized features base on threshold"""

threshold = 0.4
valid_img_features_binerizd = np.where(valid_img_features > threshold, 1, 0)

valid_predicted_cuis = my_MultiLabelBinarizer.inverse_transform(valid_img_features_binerizd)

#valid_predicted_cuis

#len(gen_valid.image_filenames)

#standard_valid_image_name = "ImageCLEFmedCaption_2022_valid_{0:06d}"
valid_df_result = ["ID\tcuis"]
i=0
for image_name in gen_valid.image_filenames:
  #image_name = standard_valid_image_name.format(image['image_id'])
  result = image_name + "\t" + ";".join(valid_predicted_cuis[i])
  valid_df_result.append(result)
  i+=1

valid_df_result.sort()
valid_df_pred = pd.DataFrame(data=valid_df_result)
valid_df_pred.to_csv(result_path + '/valid_concepts_results.csv', index=False, header=None)

"""##F1 score"""

import sys, argparse, string
import csv
import warnings

from sklearn.metrics import f1_score

min_concepts = sys.maxsize
max_concepts = 0
total_concepts = 0
concepts_distrib = {}

# Read a Tab-separated ImageID - Caption pair file
def readfile(path):
    try:
        pairs = {}
        with open(path) as csvfile:
            reader = csv.reader(csvfile, delimiter='\t', quoting=csv.QUOTE_NONE)
            for row in reader:
                # We have an ID and a set of concepts (possibly empty)
                if len(row) == 2:
                    pairs[row[0]] = row[1]
                # We only have an ID
                elif len(row) == 1:
                    pairs[row[0]] = ''
                else:
                    print('File format is wrong, please check your run file')
                    exit(1)

        return pairs
    except FileNotFoundError:
        print('File "' + path + '" not found! Please check the path!')
        exit(1)

# Print 1-level key-value dictionary, sorted (with numeric key)
def print_dict_sorted_num(obj):
    keylist = [int(x) for x in list(obj.keys())]
    keylist.sort()
    for key in keylist:
        print(key, ':', obj[str(key)])

candidate_pairs = readfile(candidate_file)
gt_pairs = readfile(gt_file)

#candidate_pairs

# Define max score and current score
max_score = len(candidate_pairs)
current_score = 0

# Check there are the same number of pairs between candidate and ground truth
# if len(candidate_pairs) != len(gt_pairs):
#     print('ERROR : Candidate does not contain the same number of entries as the ground truth!')
#     exit(1)

# Evaluate each candidate concept list against the ground truth
print('Processing concept sets...\n********************************')

i = 0
for image_key in candidate_pairs:
    if (image_key not in candidate_pairs):
      continue
    # Get candidate and GT concepts
    candidate_concepts = candidate_pairs[image_key].upper()
    gt_concepts = gt_pairs[image_key.split('.')[0]].upper()

    # Split concept string into concept array
    # Manage empty concept lists
    if gt_concepts.strip() == '':
        gt_concepts = []
    else:
        gt_concepts = gt_concepts.split(';')

    if candidate_concepts.strip() == '':
        candidate_concepts = []
    else:
        candidate_concepts = candidate_concepts.split(';')

    # Manage empty GT concepts (ignore in evaluation)
    if len(gt_concepts) == 0:
        max_score -= 1
    # Normal evaluation
    else:
        # Concepts stats
        total_concepts += len(gt_concepts)

        # Global set of concepts
        all_concepts = sorted(list(set(gt_concepts + candidate_concepts)))

        # Calculate F1 score for the current concepts
        y_true = [int(concept in gt_concepts) for concept in all_concepts]
        y_pred = [int(concept in candidate_concepts) for concept in all_concepts]

        f1score = f1_score(y_true, y_pred, average='binary')

        # Increase calculated score
        current_score += f1score

    # Concepts stats
    nb_concepts = str(len(gt_concepts))
    if nb_concepts not in concepts_distrib:
        concepts_distrib[nb_concepts] = 1
    else:
        concepts_distrib[nb_concepts] += 1

    if len(gt_concepts) > max_concepts:
        max_concepts = len(gt_concepts)

    if len(gt_concepts) < min_concepts:
        min_concepts = len(gt_concepts)

    # Progress display
    i += 1
    if i % 1000 == 0:
        print(i, '/', len(gt_pairs), ' concept sets processed...')

# Print stats
print('Concept statistics\n********************************')
print('Number of concepts distribution')
print_dict_sorted_num(concepts_distrib)
print('Least concepts in set :', min_concepts)
print('Most concepts in set :', max_concepts)
print('Average concepts in set :', total_concepts / len(candidate_pairs))

# Print evaluation result
print('Final result\n********************************')
print('Obtained score :', current_score, '/', max_score)
print('Mean score over all concept sets :', current_score / max_score)

"""#Test

Test Custom Generator
"""

class Test_Custom_Generator(tf.keras.utils.Sequence):
    def __init__(self, image_filenames, batch_size, folder_path):
        self.image_filenames = image_filenames
        self.batch_size = batch_size
        self.folder_path = folder_path
    def __len__(self):
        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(int)
    def __getitem__(self, idx):
        batch_names = self.image_filenames[idx * self.batch_size: (idx + 1) * self.batch_size]
        batch_x  = load_images(299, 299, batch_names, self.folder_path)
        batch_x = np.expand_dims(batch_x, axis=-1)
        batch_x = tf.image.grayscale_to_rgb(
            tf.convert_to_tensor(batch_x),
            name=None
        )
        return batch_x

"""create image test sets"""

test_img_names = [os.path.splitext(os.path.basename(x))[0] for x in glob.glob(test_path+'/*.jpg')][:test_number]
print(f"found {len(test_img_names)} test images")
gen_test = Test_Custom_Generator(test_img_names, dataset_batchsize, folder_path=test_path)

"""predict test images"""

test_img_features = fine_tuned_inceptionV3.predict(gen_test)

"""save predicted cui one hots to a npy file"""

with open(result_path +'test_img_features.npy', 'wb') as f:
    np.save(f,test_img_features,allow_pickle=True)

"""load predicted cui one hots from npy file"""

with open(result_path +'test_img_features.npy', 'rb') as f:
    test_img_features = np.load(f,allow_pickle=True)

"""normalized features base on threshold"""

test_img_features_binerizd = np.where(test_img_features > threshold, 1, 0)

test_predicted_cuis = my_MultiLabelBinarizer.inverse_transform(test_img_features_binerizd)

#len(test_predicted_cuis)

#len(gen_test.image_filenames)

#standard_test_image_name = "ImageCLEFmedCaption_2022_test_{0:06d}"
test_df_result = ["ID\tcuis"]
i=0
for image_name in gen_test.image_filenames:
  result = image_name + "\t" + ";".join(test_predicted_cuis[i])
  test_df_result.append(result)
  i+=1

test_df_result.sort()
test_df_pred = pd.DataFrame(data=test_df_result)
test_df_pred.to_csv(result_path + '/test_results.csv', index=False, header=None)

